{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f400ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All dependencies installed\n"
     ]
    }
   ],
   "source": [
    "# Install needed python modules\n",
    "!pip install click | grep -v 'already satisfied'\n",
    "!pip install numpy | grep -v 'already satisfied'\n",
    "!pip install requests | grep -v 'already satisfied'\n",
    "!pip install Pillow | grep -v 'already satisfied'\n",
    "!pip install torch torchvision torchaudio | grep -v 'already satisfied'\n",
    "!pip install pandas | grep -v 'already satisfied'\n",
    "!pip install scipy | grep -v 'already satisfied'\n",
    "print(\"All dependencies installed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "673c7336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All modules imported\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import os\n",
    "import re\n",
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "import click\n",
    "import dnnlib\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import torch\n",
    "\n",
    "import legacy\n",
    "from stablehash_dataset import StableHashDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "print(\"All modules imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87f55d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All variables set\n"
     ]
    }
   ],
   "source": [
    "# Set Nvidia Network model \n",
    "\n",
    "network_pkl = \"/home/ubuntu/nvidia-model/stylegan3-r-ffhq-1024x1024.pkl\"\n",
    "\n",
    "# Load training dataset and create iterator\n",
    "data_dir = \"/home/ubuntu/stablehash-reconstruct/output\"\n",
    "data_csv = \"/home/ubuntu/stablehash-reconstruct/training_data.csv\"\n",
    "train_data = StableHashDataset(data_dir, data_csv)\n",
    "train_dataloader = DataLoader(train_data, batch_size=4, shuffle=True)\n",
    "#stablehash, original_img = next(iter(train_dataloader))\n",
    "\n",
    "print(\"All variables set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f3dc64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_transform(translate: Tuple[float,float], angle: float):\n",
    "    m = np.eye(3)\n",
    "    s = np.sin(angle/360.0*np.pi*2)\n",
    "    c = np.cos(angle/360.0*np.pi*2)\n",
    "    m[0][0] = c\n",
    "    m[0][1] = s\n",
    "    m[0][2] = translate[0]\n",
    "    m[1][0] = -s\n",
    "    m[1][1] = c\n",
    "    m[1][2] = translate[1]\n",
    "    return m\n",
    "\n",
    "\n",
    "def generate_images():\n",
    "    \n",
    "    seeds = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "    truncation_psi = 0.75\n",
    "    noise_mode = \"const\"\n",
    "    outdir  = \"/home/ubuntu/stablehash-reconstruct/output\"\n",
    "    translate = 0,0\n",
    "    rotate = 0\n",
    "    class_idx = None\n",
    "    \n",
    "    # 1) Load pre-trained Generator\n",
    "    print('Loading networks from \"%s\"...' % network_pkl)\n",
    "    device = torch.device('cuda')\n",
    "    with dnnlib.util.open_url(network_pkl) as f:\n",
    "        G = legacy.load_network_pkl(f)['G_ema'].to(device) # type: ignore\n",
    "    print(\"Network loaded\")\n",
    "    \n",
    "    # 2) Define mapping and synthesis network (freeze)\n",
    "    mapping_n = G.mapping\n",
    "    synthesis_n = G.synthesis\n",
    "    for mapping_param in mapping_n.parameters(): # set mapping network params to trainable\n",
    "        mapping_param.requires_grad = True\n",
    "    for synthesis_param in synthesis_n.parameters(): # set synthesis params to frozen\n",
    "        synthesis_param.requires_grad = False\n",
    "    print(\"Defined boolean mapping\")\n",
    "    \n",
    "    # 3) Define optimizer --> in this case we use ADAM\n",
    "    optim = torch.optim.Adam(mapping_n.parameters(), lr=0.0025, betas=[0,0.99], eps=1e-8)\n",
    "    print(\"Optimizer defined\")\n",
    "    \n",
    "    # 4) Define simple MSE loss function\n",
    "    mse_loss = torch.nn.MSELoss(reduction=\"mean\")\n",
    "\n",
    "    for i in range(1000):\n",
    "        stablehash, orig_img = next(iter(train_dataloader))\n",
    "        w = G.mapping(torch.flip(stablehash, [1]), class_idx) # remove flip function --> only for testing\n",
    "        gen_img = G.synthesis(w)\n",
    "        gen_img = (gen_img * 127.5 + 128).clamp(0, 255).float()\n",
    "        loss_value = mse_loss(gen_img, orig_img)\n",
    "        loss_value.backward()\n",
    "        optim.step() #gradient descent\n",
    "        print(loss_value)\n",
    "    print(\"MSE loss function defined\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab959cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading networks from \"/home/ubuntu/nvidia-model/stylegan3-r-ffhq-1024x1024.pkl\"...\n",
      "Network loaded\n",
      "Defined boolean mapping\n",
      "Optimizer defined\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/environments/my_env/lib/python3.8/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([4, 3, 160, 160])) that is different to the input size (torch.Size([4, 3, 1024, 1024])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (1024) must match the size of tensor b (160) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgenerate_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \n",
      "Cell \u001b[0;32mIn[3], line 52\u001b[0m, in \u001b[0;36mgenerate_images\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m gen_img \u001b[38;5;241m=\u001b[39m G\u001b[38;5;241m.\u001b[39msynthesis(w)\n\u001b[1;32m     51\u001b[0m gen_img \u001b[38;5;241m=\u001b[39m (gen_img \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m127.5\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m128\u001b[39m)\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m---> 52\u001b[0m loss_value \u001b[38;5;241m=\u001b[39m \u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgen_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morig_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m loss_value\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     54\u001b[0m optim\u001b[38;5;241m.\u001b[39mstep() \u001b[38;5;66;03m#gradient descent\u001b[39;00m\n",
      "File \u001b[0;32m~/environments/my_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/environments/my_env/lib/python3.8/site-packages/torch/nn/modules/loss.py:536\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/environments/my_env/lib/python3.8/site-packages/torch/nn/functional.py:3294\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3292\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3294\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mmse_loss(expanded_input, expanded_target, _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction))\n",
      "File \u001b[0;32m~/environments/my_env/lib/python3.8/site-packages/torch/functional.py:74\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[38;5;241m*\u001b[39mtensors)\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (1024) must match the size of tensor b (160) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    " generate_images() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34a3bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31125c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
