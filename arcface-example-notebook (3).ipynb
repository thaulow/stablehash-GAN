{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BoN-6jdqnzcG"
   },
   "outputs": [],
   "source": [
    "! pip install insightface\n",
    "! pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JmqCq3Wvof5o"
   },
   "outputs": [],
   "source": [
    "import insightface\n",
    "import numpy as np\n",
    "from insightface.app import FaceAnalysis\n",
    "from insightface.data import get_image as ins_get_image\n",
    "import cv2\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "yZd9elNIteTe"
   },
   "outputs": [],
   "source": [
    "def distance(embeddings1, embeddings2, distance_type='Cosine'):\n",
    "    embeddings1=embeddings1.astype(np.float64)\n",
    "    embeddings2=embeddings2.astype(np.float64)\n",
    "    if distance_type=='Euclidian':\n",
    "        # Euclidian distance\n",
    "        embeddings1 = embeddings1/np.linalg.norm(embeddings1, axis=0, keepdims=True)\n",
    "        embeddings2 = embeddings2/np.linalg.norm(embeddings2, axis=0, keepdims=True)\n",
    "        diff = np.subtract(embeddings1, embeddings2)\n",
    "        dist = np.sum(np.square(diff),0)\n",
    "    elif distance_type=='Cosine':\n",
    "        # Distance based on cosine similarity\n",
    "        dot = np.sum(np.multiply(embeddings1, embeddings2), axis=0)\n",
    "        norm = np.linalg.norm(embeddings1, axis=0) * np.linalg.norm(embeddings2, axis=0)\n",
    "        similarity = dot/norm\n",
    "        similarity = min(1,similarity)\n",
    "        dist=1-similarity\n",
    "    else:\n",
    "        raise 'Undefined distance metric %d' % distance_metric \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "izNWIP4NoMcQ",
    "outputId": "ca059fbb-42aa-4b60-9018-4a637d8b92ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/ubuntu/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/ubuntu/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/ubuntu/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/ubuntu/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/ubuntu/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n"
     ]
    }
   ],
   "source": [
    "fr_model = insightface.app.FaceAnalysis()\n",
    "ctx_id = 0\n",
    "fr_model.prepare(ctx_id = ctx_id, det_thresh=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4JRqQx2VqLzJ",
    "outputId": "61ba5a51-fb2f-4340-f594-8c82f7c78982"
   },
   "outputs": [],
   "source": [
    "img1 = cv2.imread(\"/volumes/1/aligned/04601d33.jpg\")\n",
    "img1_mated = cv2.imread(\"/volumes/1/aligned/04535d17.jpg\")\n",
    "img2 = cv2.imread(\"/volumes/1/output/100/frgc_cluster_0.png\")\n",
    "\n",
    "face1 = fr_model.get(img1)\n",
    "face1_mated = fr_model.get(img1_mated)\n",
    "face2 = fr_model.get(img2)\n",
    "\n",
    "embedding1 = face1[0].normed_embedding\n",
    "embedding1_mated = face1_mated[0].normed_embedding\n",
    "embedding2 = face2[0].normed_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "girvjSUfs4cS",
    "outputId": "16a93f2a-25a3-4f50-d90f-f551ffa57ae1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Mated Comparison Score: 0.9607774963876917\n",
      "Mated Comparison Score: 1.0726081805424759\n"
     ]
    }
   ],
   "source": [
    "print(f\"Non-Mated Comparison Score: {distance(embedding1, embedding2)}\")\n",
    "print(f\"Mated Comparison Score: {distance(embedding1, embedding1_mated)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing cluster 0 with user IDs ['02463', '04397', '04513', '04535', '04601', '04810']\n",
      "Processing user ID:  02463\n",
      "02463d580.jpg\n",
      "02463d580.jpg\n",
      "/volumes/1/output/frgc_cluster_0.png\n",
      "Non-Mated Comparison Score: 0.9444373492891693\n",
      "Mated Comparison Score: 2.220446049250313e-16\n",
      "Processing user ID:  04397\n",
      "04397d369.jpg\n",
      "04397d369.jpg\n",
      "/volumes/1/output/frgc_cluster_0.png\n",
      "Non-Mated Comparison Score: 0.9607774963876917\n",
      "Mated Comparison Score: 0\n",
      "Processing user ID:  04513\n",
      "04513d47.jpg\n",
      "04513d47.jpg\n",
      "/volumes/1/output/frgc_cluster_0.png\n",
      "Non-Mated Comparison Score: 1.0563637498175182\n",
      "Mated Comparison Score: 0\n",
      "Processing user ID:  04535\n",
      "04535d80.jpg\n",
      "04535d80.jpg\n",
      "/volumes/1/output/frgc_cluster_0.png\n",
      "Non-Mated Comparison Score: 1.0265063704843058\n",
      "Mated Comparison Score: 0\n",
      "Processing user ID:  04601\n",
      "04601d31.jpg\n",
      "04601d31.jpg\n",
      "/volumes/1/output/frgc_cluster_0.png\n",
      "Non-Mated Comparison Score: 1.0250020165796059\n",
      "Mated Comparison Score: 0\n",
      "Processing user ID:  04810\n",
      "04810d111.jpg\n",
      "04810d111.jpg\n",
      "/volumes/1/output/frgc_cluster_0.png\n",
      "Non-Mated Comparison Score: 0.9888993697303603\n",
      "Mated Comparison Score: 0\n",
      "Processing cluster 37 with user IDs ['04200', '04337', '04524', '04633', '04817', '04865', '04879', '04927', '04933']\n",
      "Processing user ID:  04200\n",
      "04200d70.jpg\n",
      "04200d70.jpg\n",
      "/volumes/1/output/frgc_cluster_37.png\n",
      "Non-Mated Comparison Score: 1.049820768211016\n",
      "Mated Comparison Score: 2.220446049250313e-16\n",
      "Processing user ID:  04337\n",
      "04337d91.jpg\n",
      "04337d91.jpg\n",
      "/volumes/1/output/frgc_cluster_37.png\n",
      "Non-Mated Comparison Score: 0.9115372444632261\n",
      "Mated Comparison Score: 0\n",
      "Processing user ID:  04524\n",
      "04524d62.jpg\n",
      "04524d62.jpg\n",
      "/volumes/1/output/frgc_cluster_37.png\n",
      "Non-Mated Comparison Score: 1.0208130197666536\n",
      "Mated Comparison Score: 2.220446049250313e-16\n",
      "Processing user ID:  04633\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, img_filename \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(img_filenames):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# Load the current image and the next image\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/volumes/1/subjects/\u001b[39m\u001b[38;5;124m'\u001b[39m, img_filename)\n\u001b[0;32m---> 28\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(img_filename)\n\u001b[1;32m     31\u001b[0m     img_mated_filename \u001b[38;5;241m=\u001b[39m img_filenames[(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mlen\u001b[39m(img_filenames)]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open('/home/ubuntu/trainingfiles/frgc_results_cluster_id_to_subjects.txt', 'r') as f:\n",
    "    reader = csv.reader(f, delimiter=':')\n",
    "    clusters_dict = {}\n",
    "    for i, row in enumerate(reader):\n",
    "        if i < 2:  # Skip the first two rows\n",
    "            continue\n",
    "        cluster_num = int(row[0].strip())\n",
    "        user_ids = [user_id.strip()[1:-1] for user_id in row[1].strip()[1:-1].split(',')]\n",
    "        clusters_dict[cluster_num] = user_ids\n",
    "\n",
    "# Loop through the clusters in the dictionary and process the images\n",
    "for cluster_num, user_ids in clusters_dict.items():\n",
    "    print(f\"Processing cluster {cluster_num} with user IDs {user_ids}\")\n",
    "    for user_id in user_ids:\n",
    "        print(\"Processing user ID: \",user_id)\n",
    "        # Find all images in the folder that match the user_id \n",
    "        img_filenames = sorted([filename for filename in os.listdir('/volumes/1/subjects/') if filename.startswith(user_id) and filename.endswith('.jpg')])\n",
    "        \n",
    "        # If there are no matching images, skip to the next user_id\n",
    "        if not img_filenames:\n",
    "            print(\"failed\")\n",
    "            continue\n",
    "        \n",
    "        # Loop through all images for this user_id\n",
    "        for i, img_filename in enumerate(img_filenames):\n",
    "            # Load the current image and the next image\n",
    "            img_path = os.path.join('/volumes/1/subjects/', img_filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            print(img_filename)\n",
    "            \n",
    "            img_mated_filename = img_filenames[(i + 1) % len(img_filenames)]\n",
    "            img_mated_path = os.path.join('/volumes/1/subjects/', img_mated_filename)\n",
    "            img_mated = cv2.imread(img_mated_path)\n",
    "            print(img_filenames[(i + 1) % len(img_filenames)])\n",
    "            \n",
    "            img2_filename = 'frgc_cluster_{}.png'.format(cluster_num)\n",
    "            img2_path = os.path.join('/volumes/1/output/', img2_filename)\n",
    "            img2 = cv2.imread(img2_path)\n",
    "            print(img2_path)\n",
    "            \n",
    "            face = fr_model.get(img)\n",
    "            face_mated = fr_model.get(img_mated)\n",
    "            \n",
    "            # Try to get the face embedding for img2\n",
    "            try:\n",
    "                face2 = fr_model.get(img2)\n",
    "                \n",
    "                embedding = face[0].normed_embedding\n",
    "                embedding_mated = face_mated[0].normed_embedding\n",
    "                embedding2 = face2[0].normed_embedding\n",
    "                print(f\"Non-Mated Comparison Score: {distance(embedding, embedding2)}\")\n",
    "                print(f\"Mated Comparison Score: {distance(embedding, embedding_mated)}\")\n",
    "            except IndexError:\n",
    "                print(f\"No face detected in {img2_path}\")\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
